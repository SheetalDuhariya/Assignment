{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "THEORY QUESTIONS\n",
        "---\n",
        "\n",
        "1. What are the key differences between SQL and NoSQL databases?\n",
        "\n",
        "\n",
        "\n",
        "SQL databases are relational, structured with tables and use schemas, whereas NoSQL databases are non-relational, schema-less, and can handle unstructured data. SQL uses structured query language, while NoSQL offers flexible query methods depending on the type (document, key-value, etc.).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "2. What makes MongoDB a good choice for modern applications?\n",
        "\n",
        "\n",
        "\n",
        "MongoDB is schema-flexible, horizontally scalable, and document-oriented, making it ideal for applications needing rapid development, handling large volumes of data, and agile iteration.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "3. Explain the concept of collections in MongoDB.\n",
        "\n",
        "\n",
        "\n",
        "A collection in MongoDB is a group of documents stored within a database. It's the equivalent of a table in relational databases but schema-less, allowing different structures for each document.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "4. How does MongoDB ensure high availability using replication?\n",
        "\n",
        "\n",
        "\n",
        "MongoDB uses replica sets—groups of mongod instances—to maintain copies of the same data. One node is primary (handling writes/reads), while others are secondaries (for failover). If the primary fails, a secondary is automatically elected as the new primary.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "5. What are the main benefits of MongoDB Atlas?\n",
        "\n",
        "\n",
        "\n",
        "MongoDB Atlas offers managed hosting, automatic backups, scalability, security features, monitoring tools, and multi-cloud support, enabling teams to deploy and manage databases effortlessly.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "6. What is the role of indexes in MongoDB, and how do they improve performance?\n",
        "\n",
        "\n",
        "\n",
        "Indexes improve query performance by allowing MongoDB to find documents quickly without scanning every document. Common types include single-field, compound, and text indexes.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "7. Describe the stages of the MongoDB aggregation pipeline.\n",
        "Key stages include:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "$match: Filters documents.\n",
        "\n",
        "$group: Aggregates data by specified expressions.\n",
        "\n",
        "$project: Reshapes documents.\n",
        "\n",
        "$sort: Orders documents.\n",
        "\n",
        "$limit and $skip: Control pagination.\n",
        "\n",
        "$lookup: Joins documents from another collection.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "8. What is sharding in MongoDB? How does it differ from replication?\n",
        "\n",
        "\n",
        "\n",
        "Sharding is horizontal scaling where data is split across multiple servers (shards). Replication is about data redundancy and availability, while sharding is about performance and scalability.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "9. What is PyMongo, and why is it used?\n",
        "\n",
        "\n",
        "\n",
        "PyMongo is the official Python driver for MongoDB. It allows Python applications to connect to and interact with MongoDB databases, performing queries, updates, and administrative operations.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "10. What are the ACID properties in the context of MongoDB transactions?\n",
        "\n",
        "\n",
        "\n",
        "ACID stands for Atomicity, Consistency, Isolation, Durability. MongoDB transactions ensure that multi-document operations uphold these properties, providing reliable and predictable outcomes.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "11. What is the purpose of MongoDB's explain() function?\n",
        "\n",
        "\n",
        "\n",
        "explain() provides insight into how MongoDB executes a query, including index usage and execution stats. It helps in performance tuning.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "12. How does MongoDB handle schema validation?\n",
        "\n",
        "\n",
        "\n",
        "MongoDB allows optional schema validation using JSON Schema. Developers can enforce rules such as data types, required fields, and value ranges on document fields.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "13. What is the difference between a primary and a secondary node in a replica set?\n",
        "\n",
        "\n",
        "\n",
        "The primary node receives all write operations. Secondary nodes replicate data from the primary and serve as backups, promoting one to primary if needed.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "14. What security mechanisms does MongoDB provide for data protection?\n",
        "\n",
        "\n",
        "\n",
        "MongoDB offers role-based access control (RBAC), encryption-at-rest, TLS/SSL for encrypted connections, auditing, and IP whitelisting to secure data access.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "15. Explain the concept of embedded documents and when they should be used.\n",
        "\n",
        "\n",
        "\n",
        "Embedded documents are nested documents within a parent document. They are useful when data is closely related and often accessed together, reducing the need for joins.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "16. What is the purpose of MongoDB's $lookup stage in aggregation?\n",
        "\n",
        "\n",
        "\n",
        "$lookup allows joining documents from different collections based on a shared field, similar to SQL joins, enriching documents with related data.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "17. What are some common use cases for MongoDB?\n",
        "\n",
        "\n",
        "\n",
        "Common use cases include content management systems, real-time analytics, IoT, e-commerce platforms, catalogs, and mobile apps requiring flexible schemas.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "18. What are the advantages of using MongoDB for horizontal scaling?\n",
        "\n",
        "\n",
        "\n",
        "MongoDB’s sharding supports automatic data distribution across nodes, helping manage growing data volumes and read/write loads without performance degradation.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "19. How do MongoDB transactions differ from SQL transactions?\n",
        "\n",
        "\n",
        "\n",
        "While SQL supports multi-record transactions by default, MongoDB added multi-document transactions in version 4.0. They are more recent and have some limitations but ensure ACID compliance.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "20. What are the main differences between capped collections and regular collections?\n",
        "\n",
        "\n",
        "\n",
        "Capped collections have fixed sizes and work in a circular fashion (overwriting old data). Regular collections grow dynamically and do not auto-delete old data.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "21. What is the purpose of the $match stage in MongoDB's aggregation pipeline?\n",
        "\n",
        "\n",
        "\n",
        "$match filters documents to pass only those that meet specified criteria to the next pipeline stage, improving efficiency and reducing processing overhead.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "22. How can you secure access to a MongoDB database?\n",
        "\n",
        "\n",
        "\n",
        "Use authentication, role-based access, IP whitelisting, TLS/SSL encryption, and enable auditing and encryption-at-rest to ensure data and access security.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "23. What is MongoDB's WiredTiger storage engine, and why is it important?\n",
        "\n",
        "\n",
        "WiredTiger is MongoDB’s default storage engine that provides high performance, compression, and concurrency control, enabling better memory and CPU utilization."
      ],
      "metadata": {
        "id": "aCh59p9UYopd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PRACTICE QUESTIONS\n",
        "\n",
        "Q1. Write a Python script to load the Superstore dataset from a CSV file into MongoDB.\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "import json\n",
        "\n",
        "# 1. Load the Superstore dataset into MongoDB\n",
        "client = MongoClient(\"mongodb://localhost:27017/\")\n",
        "db = client[\"SuperstoreDB\"]\n",
        "orders_collection = db[\"Orders\"]\n",
        "\n",
        "df = pd.read_csv(\"superstore.csv\", encoding='ISO-8859-1')\n",
        "data = json.loads(df.to_json(orient=\"records\"))\n",
        "orders_collection.delete_many({})\n",
        "orders_collection.insert_many(data)\n",
        "print(\"1. Data inserted into MongoDB.\")\n",
        "\n",
        "# 2. Retrieve and print all documents\n",
        "print(\"2. All Orders:\")\n",
        "for order in orders_collection.find():\n",
        "    print(order)\n",
        "\n",
        "# 3. Count total documents\n",
        "count = orders_collection.count_documents({})\n",
        "print(f\"3. Total number of documents: {count}\")\n",
        "\n",
        "# 4. Fetch orders from \"West\" region\n",
        "print(\"4. Orders from the 'West' region:\")\n",
        "for doc in orders_collection.find({\"Region\": \"West\"}):\n",
        "    print(doc)\n",
        "\n",
        "# 5. Find orders where Sales > 500\n",
        "print(\"5. Orders with Sales > 500:\")\n",
        "for doc in orders_collection.find({\"Sales\": {\"$gt\": 500}}):\n",
        "    print(doc)\n",
        "\n",
        "# 6. Top 3 orders with highest Profit\n",
        "print(\"6. Top 3 orders by Profit:\")\n",
        "for doc in orders_collection.find().sort(\"Profit\", -1).limit(3):\n",
        "    print(doc)\n",
        "\n",
        "# 7. Update \"First Class\" to \"Premium Class\"\n",
        "update_result = orders_collection.update_many(\n",
        "    {\"Ship Mode\": \"First Class\"},\n",
        "    {\"$set\": {\"Ship Mode\": \"Premium Class\"}}\n",
        ")\n",
        "print(f\"7. Updated documents: {update_result.modified_count}\")\n",
        "\n",
        "# 8. Delete orders with Sales < 50\n",
        "delete_result = orders_collection.delete_many({\"Sales\": {\"$lt\": 50}})\n",
        "print(f\"8. Deleted documents: {delete_result.deleted_count}\")\n",
        "\n",
        "# 9. Aggregation: Total sales per Region\n",
        "print(\"9. Total sales per region:\")\n",
        "pipeline = [\n",
        "    {\"$group\": {\"_id\": \"$Region\", \"total_sales\": {\"$sum\": \"$Sales\"}}}\n",
        "]\n",
        "for doc in orders_collection.aggregate(pipeline):\n",
        "    print(doc)\n",
        "\n",
        "# 10. Distinct Ship Modes\n",
        "ship_modes = orders_collection.distinct(\"Ship Mode\")\n",
        "print(f\"10. Distinct Ship Modes: {ship_modes}\")\n",
        "\n",
        "# 11. Count number of orders per Category\n",
        "print(\"11. Order counts per Category:\")\n",
        "pipeline = [\n",
        "    {\"$group\": {\"_id\": \"$Category\", \"count\": {\"$sum\": 1}}}\n",
        "]\n",
        "for doc in orders_collection.aggregate(pipeline):\n",
        "    print(doc)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "2.\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset with the appropriate encoding\n",
        "df = pd.read_csv(\"/mnt/data/superstore.csv\", encoding='ISO-8859-1')\n",
        "\n",
        "# Print all documents (rows)\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Question 3: Count and display the total number of documents in the Orders collection.\n",
        "\n",
        "Answer:\n",
        "\n",
        "The total number of documents (rows) in the Orders collection is:\n",
        "\n",
        "total_documents = len(df)\n",
        "print(total_documents)\n",
        "\n",
        "Output:\n",
        "\n",
        "9994\n",
        "\n",
        "There are 9,994 documents in total.\n",
        "\n",
        "\n",
        "Question 4: Write a query to fetch all orders from the \"West\" region.\n",
        "\n",
        "Answer:\n",
        "\n",
        "To fetch all orders from the \"West\" region in the Superstore dataset, you can use the following query in Python (using pandas):\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"superstore.csv\", encoding='ISO-8859-1')\n",
        "\n",
        "# Filter orders from the West region\n",
        "orders_west_region = df[df['Region'] == 'West']\n",
        "\n",
        "# Display the results\n",
        "print(orders_west_region)\n",
        "\n",
        "This command returns all rows (documents) where the Region is \"West\". Here’s a preview of some of those results:\n",
        "\n",
        "Row ID\tOrder ID\tOrder Date\tShip Mode\tCustomer Name\tRegion\tProduct Name\tSales\n",
        "\n",
        "3\tCA-2016-138688\t6/12/2016\tSecond Class\tDarrin Van Huff\tWest\tSelf-Adhesive Address Labels for Typewriters\t14.620\n",
        "6\tCA-2014-115812\t6/9/2014\tStandard Class\tBrosina Hoffman\tWest\tEldon Expressions Wood and Plastic Desk Accessories\t48.860\n",
        "\n",
        "\n",
        "Question 5: Write a query to find orders where Sales is greater than 500.\n",
        "\n",
        "Code (using Python and pandas):\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('superstore.csv', encoding='ISO-8859-1')\n",
        "\n",
        "# Filter for orders where Sales > 500\n",
        "high_sales_orders = df[df['Sales'] > 500]\n",
        "\n",
        "# Display selected columns\n",
        "result = high_sales_orders[['Order ID', 'Customer Name', 'Sales']]\n",
        "print(result)\n",
        "\n",
        "\n",
        "\n",
        "Question 6\n",
        "\n",
        "Fetch the top 3 orders with the highest Profit.\n",
        "\n",
        "Answer:\n",
        "\n",
        "Rank\tOrder ID\tCustomer Name\tTotal Profit\n",
        "\n",
        "1\tCA-2016-118689\tTamara Chand\t8762.39\n",
        "2\tCA-2017-140151\tRaymond Buch\t6734.47\n",
        "3\tCA-2017-166709\tHunter Lopez\t5039.99\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Code Used:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset with proper encoding\n",
        "df = pd.read_csv('superstore.csv', encoding='ISO-8859-1')\n",
        "\n",
        "# Group by Order ID and sum profits\n",
        "top_orders = df.groupby('Order ID')['Profit'].sum().reset_index()\n",
        "\n",
        "# Sort and fetch top 3\n",
        "top_3_orders = top_orders.sort_values(by='Profit', ascending=False).head(3)\n",
        "\n",
        "# Merge with original data to get customer names\n",
        "top_3_order_details = df[df['Order ID'].isin(top_3_orders['Order ID'])]\n",
        "\n",
        "# Display final order summary\n",
        "top_3_order_summary = top_3_order_details[['Order ID', 'Customer Name', 'Profit']].drop_duplicates()\n",
        "\n",
        "\n",
        "\n",
        "Question 7:\n",
        "Update all orders with Ship Mode as \"First Class\" to \"Premium Class.\"\n",
        "\n",
        "Answer:\n",
        "All entries in the \"Ship Mode\" column with the value \"First Class\" have been successfully updated to \"Premium Class.\" The updated counts for each Ship Mode are:\n",
        "\n",
        "Standard Class: 5968\n",
        "\n",
        "Second Class: 1945\n",
        "\n",
        "Premium Class: 1538\n",
        "\n",
        "Same Day: 543\n",
        "\n",
        "\n",
        "Code Used:\n",
        "\n",
        "# Read the dataset with the appropriate encoding\n",
        "df = pd.read_csv(\"superstore.csv\", encoding='ISO-8859-1')\n",
        "\n",
        "# Replace \"First Class\" with \"Premium Class\"\n",
        "df['Ship Mode'] = df['Ship Mode'].replace('First Class', 'Premium Class')\n",
        "\n",
        "# Save the updated dataset\n",
        "df.to_csv(\"superstore_updated.csv\", index=False)\n",
        "\n",
        "# View the updated counts\n",
        "print(df['Ship Mode'].value_counts())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "8: Delete all orders where Sales is less than 50.\n",
        "\n",
        "Answer:\n",
        "We removed all rows where the Sales value was less than 50.\n",
        "\n",
        "Original number of orders: 9,994\n",
        "\n",
        "Remaining orders after deletion: 5,145\n",
        "\n",
        "\n",
        "Python Code:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset with proper encoding\n",
        "df = pd.read_csv(\"superstore.csv\", encoding='ISO-8859-1')\n",
        "\n",
        "# Filter out orders where Sales is less than 50\n",
        "df_filtered = df[df['Sales'] >= 50]\n",
        "\n",
        "# Save the filtered dataset (optional)\n",
        "df_filtered.to_csv(\"superstore_filtered.csv\", index=False)\n",
        "\n",
        "# Show counts\n",
        "print(\"Original orders:\", len(df))\n",
        "print(\"Remaining orders after deletion:\", len(df_filtered))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "9. Use aggregation to group orders by Region and calculate total sales per region.\n",
        "\n",
        "Answer:\n",
        "\n",
        "Using the Superstore dataset, we grouped the orders by the Region column and summed up the Sales for each region.\n",
        "\n",
        "Result:\n",
        "\n",
        "Region\tTotal Sales\n",
        "\n",
        "West\t725,457.82\n",
        "East\t678,781.24\n",
        "Central\t501,239.89\n",
        "South\t391,721.91\n",
        "\n",
        "\n",
        "Python Code:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset with appropriate encoding\n",
        "df = pd.read_csv('/mnt/data/superstore.csv', encoding='ISO-8859-1')\n",
        "\n",
        "# Group by Region and sum Sales\n",
        "sales_by_region = df.groupby('Region')['Sales'].sum().reset_index().sort_values(by='Sales', ascending=False)\n",
        "print(sales_by_region)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "9. Use aggregation to group orders by Region and calculate total sales per region.\n",
        "\n",
        "Answer:\n",
        "\n",
        "Using the Superstore dataset, we grouped the orders by the Region column and summed up the Sales for each region.\n",
        "\n",
        "Result:\n",
        "\n",
        "Region\tTotal Sales\n",
        "\n",
        "West\t725,457.82\n",
        "East\t678,781.24\n",
        "Central\t501,239.89\n",
        "South\t391,721.91\n",
        "\n",
        "\n",
        "Python Code:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset with appropriate encoding\n",
        "df = pd.read_csv('/mnt/data/superstore.csv', encoding='ISO-8859-1')\n",
        "\n",
        "# Group by Region and sum Sales\n",
        "sales_by_region = df.groupby('Region')['Sales'].sum().reset_index().sort_values(by='Sales', ascending=False)\n",
        "print(sales_by_region)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Question 10: Fetch all distinct values for Ship Mode from the collection.\n",
        "\n",
        "Answer: The distinct values for Ship Mode in the Superstore dataset are:\n",
        "\n",
        "Second Class\n",
        "\n",
        "Standard Class\n",
        "\n",
        "First Class\n",
        "\n",
        "Same Day\n",
        "\n",
        "\n",
        "Code:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"superstore.csv\", encoding=\"ISO-8859-1\")\n",
        "\n",
        "# Fetch all distinct values for Ship Mode\n",
        "distinct_ship_modes = df['Ship Mode'].unique().tolist()\n",
        "print(distinct_ship_modes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Question 11: Count the number of orders for each category.\n",
        "\n",
        "Answer:\n",
        "\n",
        "Category          Number of Orders\n",
        "---------------------------------\n",
        "Furniture                1764\n",
        "Office Supplies          3742\n",
        "Technology               1544\n",
        "\n",
        "Code Used:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset with appropriate encoding\n",
        "df = pd.read_csv('superstore.csv', encoding='ISO-8859-1')\n",
        "\n",
        "# Count the number of unique orders for each category\n",
        "orders_per_category = df.groupby('Category')['Order ID'].nunique().reset_index()\n",
        "orders_per_category.columns = ['Category', 'Number of Orders']\n",
        "print(orders_per_category)"
      ],
      "metadata": {
        "id": "7TyOVUcNZswy"
      }
    }
  ]
}